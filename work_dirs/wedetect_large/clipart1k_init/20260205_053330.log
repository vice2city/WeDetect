2026/02/05 05:33:31 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.19 (main, Jan 27 2026, 23:59:05) [Clang 21.1.4 ]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1203406542
    GPU 0,2,3,4,5,7,8: NVIDIA TITAN RTX
    GPU 1,6: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: cc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.5.1+cu124
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.20.1+cu124
    OpenCV: 4.13.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1203406542
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2026/02/05 05:33:32 - mmengine - INFO - Config:
artaxor_evaluator = dict(
    ann_file='data/ArTaxOr/annotations/test.json',
    metric='bbox',
    type='CocoMetric')
artaxor_val_dataset = dict(
    class_text_path='data/texts/artaxor_zh_class_texts.json',
    dataset=dict(
        ann_file='annotations/test.json',
        batch_shapes_cfg=None,
        data_prefix=dict(img='test'),
        data_root='data/ArTaxOr',
        metainfo=dict(classes='data/texts/artaxor_class_texts.json'),
        test_mode=True,
        type='WeCocoDataset'),
    pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(scale=(
            1280,
            1280,
        ), type='WeDetectKeepRatioResize'),
        dict(
            allow_scale_up=False,
            pad_val=dict(img=114),
            scale=(
                1280,
                1280,
            ),
            type='WeDetectLetterResize'),
        dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
        dict(type='LoadText'),
        dict(
            meta_keys=(
                'img_id',
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
                'pad_param',
                'texts',
            ),
            type='PackDetInputs'),
    ],
    type='MultiModalDataset')
backend_args = None
base_lr = 0.0005
clipart1k_evaluator = dict(
    ann_file='data/clipart1k/annotations/test.json',
    metric='bbox',
    type='CocoMetric')
clipart1k_val_dataset = dict(
    class_text_path='data/texts/clipart1k_zh_class_texts.json',
    dataset=dict(
        ann_file='annotations/test.json',
        batch_shapes_cfg=None,
        data_prefix=dict(img='test'),
        data_root='data/clipart1k',
        debug_mode=False,
        metainfo=dict(classes='data/texts/clipart1k_class_texts.json'),
        test_mode=True,
        type='WeCocoDataset'),
    pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(scale=(
            1280,
            1280,
        ), type='WeDetectKeepRatioResize'),
        dict(
            allow_scale_up=False,
            pad_val=dict(img=114),
            scale=(
                1280,
                1280,
            ),
            type='WeDetectLetterResize'),
        dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
        dict(type='LoadText'),
        dict(
            meta_keys=(
                'img_id',
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
                'pad_param',
                'texts',
            ),
            type='PackDetInputs'),
    ],
    type='MultiModalDataset')
close_mosaic_epochs = 2
coco_evaluator = dict(
    ann_file='data/coco/annotations/instances_val2017.json',
    metric='bbox',
    type='CocoMetric')
coco_val_dataset = dict(
    class_text_path='data/texts/coco_zh_class_texts.json',
    dataset=dict(
        ann_file='data/coco/annotations/instances_val2017.json',
        batch_shapes_cfg=None,
        data_prefix=dict(img='val2017'),
        data_root='data/coco/',
        test_mode=True,
        type='WeCocoDataset'),
    pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(scale=(
            1280,
            1280,
        ), type='WeDetectKeepRatioResize'),
        dict(
            allow_scale_up=False,
            pad_val=dict(img=114),
            scale=(
                1280,
                1280,
            ),
            type='WeDetectLetterResize'),
        dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
        dict(type='LoadText'),
        dict(
            meta_keys=(
                'img_id',
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
                'pad_param',
                'texts',
            ),
            type='PackDetInputs'),
    ],
    type='MultiModalDataset')
current_dataset = 'clipart1k'
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'wedetect',
    ])
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='mmdet.DetVisualizationHook'))
default_scope = 'mmdet'
dist_cfg = dict(backend='nccl', timeout=10800)
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
find_unused_parameters = True
fish_evaluator = dict(
    ann_file='data/fish/annotations/test.json',
    metric='bbox',
    type='CocoMetric')
fish_val_dataset = dict(
    class_text_path='data/texts/fish_zh_class_texts.json',
    dataset=dict(
        ann_file='annotations/test.json',
        batch_shapes_cfg=None,
        data_prefix=dict(img='test'),
        data_root='data/FISH',
        metainfo=dict(classes='data/texts/fish_class_texts.json'),
        test_mode=True,
        type='WeCocoDataset'),
    pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(scale=(
            1280,
            1280,
        ), type='WeDetectKeepRatioResize'),
        dict(
            allow_scale_up=False,
            pad_val=dict(img=114),
            scale=(
                1280,
                1280,
            ),
            type='WeDetectLetterResize'),
        dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
        dict(type='LoadText'),
        dict(
            meta_keys=(
                'img_id',
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
                'pad_param',
                'texts',
            ),
            type='PackDetInputs'),
    ],
    type='MultiModalDataset')
img_scale = (
    1280,
    1280,
)
launcher = 'none'
load_from = 'checkpoints/WeDetect/wedetect_large.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
loss_bbox_weight = 7.5
loss_cls_weight = 0.5
loss_dfl_weight = 0.375
lvis_minival_dataset = dict(
    class_text_path='data/texts/lvis_v1_zh_class_texts.json',
    dataset=dict(
        ann_file='data/lvis/lvis_v1_minival_inserted_image_name.json',
        batch_shapes_cfg=None,
        data_prefix=dict(img=''),
        data_root='data/coco/',
        test_mode=True,
        type='YOLOv5LVISV1Dataset'),
    pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(scale=(
            1280,
            1280,
        ), type='WeDetectKeepRatioResize'),
        dict(
            allow_scale_up=False,
            pad_val=dict(img=114),
            scale=(
                1280,
                1280,
            ),
            type='WeDetectLetterResize'),
        dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
        dict(type='LoadText'),
        dict(
            meta_keys=(
                'img_id',
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
                'pad_param',
                'texts',
            ),
            type='PackDetInputs'),
    ],
    type='MultiModalDataset')
lvis_minival_evaluator = dict(
    ann_file='data/lvis/lvis_v1_minival_inserted_image_name.json',
    metric='bbox',
    type='LVISMetric')
lvis_od_val_dataset = dict(
    class_text_path='data/texts/lvis_v1_zh_class_texts.json',
    dataset=dict(
        ann_file='data/lvis/lvis_od_val.json',
        batch_shapes_cfg=None,
        data_prefix=dict(img=''),
        data_root='data/coco/',
        test_mode=True,
        type='YOLOv5LVISV1Dataset'),
    pipeline=[
        dict(backend_args=None, type='LoadImageFromFile'),
        dict(scale=(
            1280,
            1280,
        ), type='WeDetectKeepRatioResize'),
        dict(
            allow_scale_up=False,
            pad_val=dict(img=114),
            scale=(
                1280,
                1280,
            ),
            type='WeDetectLetterResize'),
        dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
        dict(type='LoadText'),
        dict(
            meta_keys=(
                'img_id',
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
                'pad_param',
                'texts',
            ),
            type='PackDetInputs'),
    ],
    type='MultiModalDataset')
lvis_od_val_evaluator = dict(
    ann_file='data/lvis/lvis_od_val.json', metric='bbox', type='LVISMetric')
max_epochs = 80
model = dict(
    backbone=dict(
        image_model=dict(
            frozen_modules=[],
            model_name='large',
            type='ConvNextVisionBackbone'),
        text_model=dict(
            frozen_modules=[],
            model_name='./xlm-roberta-large/',
            model_size='large',
            type='XLMRobertaLanguageBackbone'),
        type='MultiModalYOLOBackbone'),
    bbox_head=dict(
        bbox_coder=dict(type='WeDetectDistancePointBBoxCoder'),
        head_module=dict(
            embed_dims=768,
            in_channels=[
                256,
                512,
                1024,
            ],
            model_size='large',
            num_classes=80,
            type='YOLOWorldHeadModule',
            use_bn_head=True),
        loss_bbox=dict(
            bbox_format='xyxy',
            iou_mode='ciou',
            loss_weight=7.5,
            reduction='sum',
            return_iou=False,
            type='mmyoloIoULoss'),
        loss_cls=dict(
            loss_weight=0.5,
            reduction='none',
            type='CrossEntropyLoss',
            use_sigmoid=True),
        loss_dfl=dict(
            loss_weight=0.375, reduction='mean', type='DistributionFocalLoss'),
        prior_generator=dict(
            offset=0.5, strides=[
                8,
                16,
                32,
            ], type='MlvlPointGenerator'),
        type='YOLOWorldHead'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            0.0,
            0.0,
            0.0,
        ],
        std=[
            255.0,
            255.0,
            255.0,
        ],
        type='YOLOWDetDataPreprocessor'),
    mm_neck=False,
    neck=dict(model_size='large', scale_factor=1.5, type='CSPRepBiFPANNeck'),
    num_test_classes=1203,
    num_train_classes=80,
    test_cfg=dict(
        max_per_img=300,
        multi_label=True,
        nms=dict(iou_threshold=0.7, type='nms'),
        nms_pre=30000,
        score_thr=0.001),
    train_cfg=dict(
        assigner=dict(
            alpha=0.5,
            beta=6.0,
            eps=1e-09,
            num_classes=1203,
            topk=10,
            type='BatchTaskAlignedAssigner',
            use_ciou=True)),
    type='YOLOWorldDetector')
model_test_cfg = dict(
    max_per_img=300,
    multi_label=True,
    nms=dict(iou_threshold=0.7, type='nms'),
    nms_pre=30000,
    score_thr=0.001)
neck_embed_channels = [
    128,
    256,
    512,
]
neck_num_heads = [
    4,
    8,
    16,
]
num_classes = 1203
num_training_classes = 80
resume = False
save_epoch_intervals = 1
tal_alpha = 0.5
tal_beta = 6.0
tal_topk = 10
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        class_text_path='data/texts/clipart1k_zh_class_texts.json',
        dataset=dict(
            ann_file='annotations/test.json',
            batch_shapes_cfg=None,
            data_prefix=dict(img='test'),
            data_root='data/clipart1k',
            debug_mode=False,
            metainfo=dict(classes='data/texts/clipart1k_class_texts.json'),
            test_mode=True,
            type='WeCocoDataset'),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(scale=(
                1280,
                1280,
            ), type='WeDetectKeepRatioResize'),
            dict(
                allow_scale_up=False,
                pad_val=dict(img=114),
                scale=(
                    1280,
                    1280,
                ),
                type='WeDetectLetterResize'),
            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
            dict(type='LoadText'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'pad_param',
                    'texts',
                ),
                type='PackDetInputs'),
        ],
        type='MultiModalDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='data/clipart1k/annotations/test.json',
    metric='bbox',
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(scale=(
        1280,
        1280,
    ), type='WeDetectKeepRatioResize'),
    dict(
        allow_scale_up=False,
        pad_val=dict(img=114),
        scale=(
            1280,
            1280,
        ),
        type='WeDetectLetterResize'),
    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
    dict(type='LoadText'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
            'pad_param',
            'texts',
        ),
        type='PackDetInputs'),
]
text_channels = 768
train_batch_size_per_gpu = 10
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        class_text_path='data/texts/clipart1k_zh_class_texts.json',
        dataset=dict(
            ann_file='annotations/test.json',
            batch_shapes_cfg=None,
            data_prefix=dict(img='test'),
            data_root='data/clipart1k',
            debug_mode=False,
            metainfo=dict(classes='data/texts/clipart1k_class_texts.json'),
            test_mode=True,
            type='WeCocoDataset'),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(scale=(
                1280,
                1280,
            ), type='WeDetectKeepRatioResize'),
            dict(
                allow_scale_up=False,
                pad_val=dict(img=114),
                scale=(
                    1280,
                    1280,
                ),
                type='WeDetectLetterResize'),
            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
            dict(type='LoadText'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'pad_param',
                    'texts',
                ),
                type='PackDetInputs'),
        ],
        type='MultiModalDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_dataset_list = dict(
    artaxor=dict(
        class_text_path='data/texts/artaxor_zh_class_texts.json',
        dataset=dict(
            ann_file='annotations/test.json',
            batch_shapes_cfg=None,
            data_prefix=dict(img='test'),
            data_root='data/ArTaxOr',
            metainfo=dict(classes='data/texts/artaxor_class_texts.json'),
            test_mode=True,
            type='WeCocoDataset'),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(scale=(
                1280,
                1280,
            ), type='WeDetectKeepRatioResize'),
            dict(
                allow_scale_up=False,
                pad_val=dict(img=114),
                scale=(
                    1280,
                    1280,
                ),
                type='WeDetectLetterResize'),
            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
            dict(type='LoadText'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'pad_param',
                    'texts',
                ),
                type='PackDetInputs'),
        ],
        type='MultiModalDataset'),
    clipart1k=dict(
        class_text_path='data/texts/clipart1k_zh_class_texts.json',
        dataset=dict(
            ann_file='annotations/test.json',
            batch_shapes_cfg=None,
            data_prefix=dict(img='test'),
            data_root='data/clipart1k',
            debug_mode=False,
            metainfo=dict(classes='data/texts/clipart1k_class_texts.json'),
            test_mode=True,
            type='WeCocoDataset'),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(scale=(
                1280,
                1280,
            ), type='WeDetectKeepRatioResize'),
            dict(
                allow_scale_up=False,
                pad_val=dict(img=114),
                scale=(
                    1280,
                    1280,
                ),
                type='WeDetectLetterResize'),
            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
            dict(type='LoadText'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'pad_param',
                    'texts',
                ),
                type='PackDetInputs'),
        ],
        type='MultiModalDataset'),
    fish=dict(
        class_text_path='data/texts/fish_zh_class_texts.json',
        dataset=dict(
            ann_file='annotations/test.json',
            batch_shapes_cfg=None,
            data_prefix=dict(img='test'),
            data_root='data/FISH',
            metainfo=dict(classes='data/texts/fish_class_texts.json'),
            test_mode=True,
            type='WeCocoDataset'),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(scale=(
                1280,
                1280,
            ), type='WeDetectKeepRatioResize'),
            dict(
                allow_scale_up=False,
                pad_val=dict(img=114),
                scale=(
                    1280,
                    1280,
                ),
                type='WeDetectLetterResize'),
            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),
            dict(type='LoadText'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'pad_param',
                    'texts',
                ),
                type='PackDetInputs'),
        ],
        type='MultiModalDataset'))
val_evaluator = dict(
    ann_file='data/clipart1k/annotations/test.json',
    metric='bbox',
    type='CocoMetric')
val_evaluator_list = dict(
    artaxor=dict(
        ann_file='data/ArTaxOr/annotations/test.json',
        metric='bbox',
        type='CocoMetric'),
    clipart1k=dict(
        ann_file='data/clipart1k/annotations/test.json',
        metric='bbox',
        type='CocoMetric'),
    fish=dict(
        ann_file='data/fish/annotations/test.json',
        metric='bbox',
        type='CocoMetric'))
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='mmdet.DetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
weight_decay = 0.025
work_dir = './work_dirs/wedetect_large'

2026/02/05 05:33:50 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2026/02/05 05:33:50 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2026/02/05 05:33:54 - mmengine - INFO - Load checkpoint from checkpoints/WeDetect/wedetect_large.pth
2026/02/05 05:34:11 - mmengine - INFO - Epoch(test) [ 50/500]    eta: 0:02:25  time: 0.3243  data_time: 0.0034  memory: 3843  
2026/02/05 05:34:26 - mmengine - INFO - Epoch(test) [100/500]    eta: 0:02:05  time: 0.3030  data_time: 0.0005  memory: 3843  
2026/02/05 05:34:41 - mmengine - INFO - Epoch(test) [150/500]    eta: 0:01:48  time: 0.3053  data_time: 0.0006  memory: 3843  
2026/02/05 05:34:56 - mmengine - INFO - Epoch(test) [200/500]    eta: 0:01:33  time: 0.3076  data_time: 0.0006  memory: 3843  
2026/02/05 05:35:12 - mmengine - INFO - Epoch(test) [250/500]    eta: 0:01:17  time: 0.3090  data_time: 0.0005  memory: 3843  
2026/02/05 05:35:28 - mmengine - INFO - Epoch(test) [300/500]    eta: 0:01:02  time: 0.3124  data_time: 0.0005  memory: 3843  
2026/02/05 05:35:43 - mmengine - INFO - Epoch(test) [350/500]    eta: 0:00:46  time: 0.3123  data_time: 0.0005  memory: 3843  
2026/02/05 05:35:59 - mmengine - INFO - Epoch(test) [400/500]    eta: 0:00:31  time: 0.3155  data_time: 0.0005  memory: 3843  
2026/02/05 05:36:15 - mmengine - INFO - Epoch(test) [450/500]    eta: 0:00:15  time: 0.3211  data_time: 0.0005  memory: 3843  
2026/02/05 05:36:31 - mmengine - INFO - Epoch(test) [500/500]    eta: 0:00:00  time: 0.3253  data_time: 0.0005  memory: 3843  
2026/02/05 05:36:32 - mmengine - INFO - Evaluating bbox...
2026/02/05 05:36:34 - mmengine - INFO - bbox_mAP_copypaste: 0.499 0.782 0.543 0.274 0.505 0.568
2026/02/05 05:36:34 - mmengine - INFO - Epoch(test) [500/500]    coco/bbox_mAP: 0.4990  coco/bbox_mAP_50: 0.7820  coco/bbox_mAP_75: 0.5430  coco/bbox_mAP_s: 0.2740  coco/bbox_mAP_m: 0.5050  coco/bbox_mAP_l: 0.5680  data_time: 0.0008  time: 0.3136
